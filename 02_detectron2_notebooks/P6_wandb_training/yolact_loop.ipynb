{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python train.py --config=yolact_pp_101_ordered_rc_ucb_gait_config --resume=weights/yolact_plus_base_54_800000.pth --start_iter=0 --batch_size=5 --lr=0.0001 --momentum 0.6 --gamma 0.1 --save_interval 1000 --validation_size 1000 --keep_latest_interval 1000 --validation_iter 1000 --only_last_layer 2>&1 | tee \"yolact_pp_ordered_101_rc_ucb_gait.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_yolact():\n",
    "    FFMPEG_BIN = \"python\"\n",
    "    command = [ FFMPEG_BIN,'/home/josmar/proyectos/yolact/train.py',\n",
    "                '--config', 'yolact_pp_101_ordered_rc_ucb_gait_config', \n",
    "                '--resume', '/home/josmar/proyectos/yolact/weights/yolact_plus_base_54_800000.pth',\n",
    "                '--start_iter', str(0),\n",
    "                '--batch_size', str(5),\n",
    "                '--lr', str(0.0001),\n",
    "                '--momentum', str(0.6),\n",
    "                '--gamma', str(0.1),\n",
    "                '--save_interval', str(1000),\n",
    "                '--validation_size', str(1000),\n",
    "                '--keep_latest_interval', str(1000),\n",
    "                '--validation_iter', str(1000),\n",
    "                '--only_last_layer']\n",
    "\n",
    "    print(\"Starting training script ...\")\n",
    "    sp.run(command)\n",
    "    print(\"Finished training script ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Starting training script ...\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b47bf9ceac22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_yolact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-1d644177de4e>\u001b[0m in \u001b[0;36mtrain_yolact\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training script ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished training script ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/yolact-plus/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/yolact-plus/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/yolact-plus/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout, endtime)\u001b[0m\n\u001b[1;32m   1475\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1477\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1478\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/yolact-plus/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1422\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1424\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1425\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_yolact()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying other method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/josmar/proyectos/yolact')\n",
    "\n",
    "from data import *\n",
    "from utils.augmentations import SSDAugmentation, BaseTransform, FastBaseTransform, Resize\n",
    "from utils.functions import MovingAverage, SavePath\n",
    "from utils.logger import Log\n",
    "from utils import timer\n",
    "from layers.modules import MultiBoxLoss\n",
    "from layers.output_utils import postprocess, undo_image_transformation #To vuisualize\n",
    "from yolact import Yolact\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math, random\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import argparse\n",
    "import datetime\n",
    "import wandb\n",
    "import random\n",
    "\n",
    "# Oof\n",
    "import eval as eval_script\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_images (my_args, n_imgs):\n",
    "    global args\n",
    "    args = my_args\n",
    "    if args.config is not None:\n",
    "        set_cfg(args.config)\n",
    "\n",
    "    if args.trained_model == 'interrupt':\n",
    "        args.trained_model = SavePath.get_interrupt('weights/')\n",
    "    elif args.trained_model == 'latest':\n",
    "        args.trained_model = SavePath.get_latest('weights/', cfg.name)\n",
    "\n",
    "    if args.config is None:\n",
    "        model_path = SavePath.from_str(args.trained_model)\n",
    "        # TODO: Bad practice? Probably want to do a name lookup instead.\n",
    "        args.config = model_path.model_name + '_config'\n",
    "        print('Config not specified. Parsed %s from the file name.\\n' % args.config)\n",
    "        set_cfg(args.config)\n",
    "\n",
    "    # if args.detect:\n",
    "    #     cfg.eval_mask_branch = False\n",
    "\n",
    "    # if args.dataset is not None:\n",
    "    #     set_dataset(args.dataset)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # if not os.path.exists('results'):\n",
    "        #     os.makedirs('results')\n",
    "\n",
    "        cudnn.fastest = True\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "        \n",
    "        \n",
    "        print('Loading model...', end='')\n",
    "        net = Yolact()\n",
    "        net.load_weights(args.trained_model)\n",
    "        net.eval()\n",
    "        print(' Done.')\n",
    "        \n",
    "        net = net.cuda()\n",
    "\n",
    "        return evaluate(net, n_imgs)\n",
    "\n",
    "def evaluate(net:Yolact, train_mode=False, n_imgs = 3):\n",
    "    net.detect.use_fast_nms = True\n",
    "    net.detect.use_cross_class_nms = False\n",
    "    cfg.mask_proto_debug = False\n",
    "    \n",
    "    top_k = 15\n",
    "    th = 0.4\n",
    "    mask_alpha = 1\n",
    "\n",
    "    test_imgs = os.listdir(cfg.dataset.test_images)\n",
    "    \n",
    "    class_labels = {\n",
    "        1: \"person 1\",\n",
    "        2: \"person 2\",\n",
    "        3: \"person 3\"\n",
    "        }\n",
    "\n",
    "    wandb_imgs = []\n",
    "    for img_path in random.sample(test_imgs, n_imgs):\n",
    "        img_path = os.path.join(cfg.dataset.test_images, img_path)\n",
    "        print(img_path)\n",
    "\n",
    "        # Find predictions for the selected path\n",
    "        preds = evalimage(net=net, path = img_path)\n",
    "        \n",
    "        # Load the image and change it to RGB\n",
    "        im = cv2.imread(img_path)\n",
    "        rgb_im = im[:, :, ::-1]\n",
    "\n",
    "        # Getting image size\n",
    "        h,w,_ = rgb_im.shape\n",
    "        \n",
    "        #Process predictions\n",
    "        save = cfg.rescore_bbox\n",
    "        cfg.rescore_bbox = True\n",
    "        t = postprocess(preds, w, h, visualize_lincomb = False,\n",
    "                                            crop_masks        = True,\n",
    "                                            score_threshold   = th)\n",
    "        cfg.rescore_bbox = save\n",
    "\n",
    "        idx = t[1].argsort(0, descending=True)[:15]\n",
    "        #Getting masks,classes scores and boxes from the prediction\n",
    "        masks = t[3][idx]\n",
    "        classes, scores, boxes = [x[idx].cpu().numpy() for x in t[:3]]\n",
    "        \n",
    "        # Formatting results into wandb\n",
    "        bin_mask= np.zeros((h, w))\n",
    "        box_data = []\n",
    "        \n",
    "        class2name = {0:\"person\"}\n",
    "        for j in range(classes.shape[0]):\n",
    "            if scores[j] > th:\n",
    "                # masks\n",
    "                sil = masks[j].byte().cpu().numpy()\n",
    "                av_mask = bin_mask == 0 # Gets the pixels that are not used \n",
    "                corrected_sil = np.bitwise_and(av_mask, sil) #Gets the silhouette cropping the overlapped parts\n",
    "                bin_mask+= corrected_sil * (j+1)\n",
    "\n",
    "                # scores \n",
    "                acc = scores[j]\n",
    "                acc = round(float(acc), 2)\n",
    "\n",
    "                #boxes\n",
    "                x_min, y_min, x_max, y_max = boxes[j]\n",
    "                x_min, x_max = round(x_min/w, 2), round(x_max/w, 2)\n",
    "                y_min, y_max = round(y_min/h, 2), round(y_max/h, 2)\n",
    "                bbox_dict = {\"position\": {\n",
    "                                \"minX\": x_min,\n",
    "                                \"maxX\": x_max,\n",
    "                                \"minY\": y_min,\n",
    "                                \"maxY\": y_max},\n",
    "                            \"class_id\" : j+1,\n",
    "                            \"box_caption\": \"person:{}\".format(acc),\n",
    "                            \"scores\" : {\n",
    "                                \"acc\": acc},\n",
    "                            }\n",
    "                box_data.append(bbox_dict)\n",
    "\n",
    "                #class_labels\n",
    "                # class_str = class2name[classes[j]]+ \" \" + str(j+1)\n",
    "                # class_labels[j+1] = class_str\n",
    "        wandb_img = wandb.Image(rgb_im, \n",
    "        masks={\"prediction\" : {\"mask_data\" : bin_mask, \"class_labels\" : class_labels}},\n",
    "        boxes={\"prediction\" : {\"box_data\" : box_data, \"class_labels\" : class_labels}})\n",
    "        wandb_imgs.append(wandb_img)\n",
    "        # plt.imshow(bin_mask)\n",
    "        # plt.show()\n",
    "        # plt.imshow(rgb_im)\n",
    "        # plt.show()\n",
    "        # print(box_data)\n",
    "    return wandb_imgs\n",
    "        \n",
    "\n",
    "def evalimage(net:Yolact, path:str):\n",
    "    input_img = cv2.imread(path)\n",
    "    frame = torch.from_numpy(input_img).cuda().float()\n",
    "    batch = FastBaseTransform()(frame.unsqueeze(0))\n",
    "    preds = net(batch)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, config):\n",
    "        self.batch_size = 5\n",
    "        self.resume = \"yolact_data/weights/yolact_plus_base_54_800000.pth\"\n",
    "        self.start_iter = 0\n",
    "        self.num_workers = 4\n",
    "        self.cuda = True\n",
    "        self.lr = config.lr\n",
    "        self.momentum = config.momentum #0.6\n",
    "        self.decay = config.decay\n",
    "        self.gamma = None\n",
    "        self.save_folder = 'yolact_data/train_weights/'\n",
    "        self.log_folder = 'yolact_data/logs/'\n",
    "        self.config = \"yolact_pp_101_ordered_rc_ucb_gait_config\"\n",
    "        self.save_interval = 1000 #10000\n",
    "        self.validation_size = 1000 #5000\n",
    "        self.validation_iter = 1000 #10000\n",
    "        self.keep_latest = False\n",
    "        self.keep_latest_interval = 1000\n",
    "        self.dataset = None\n",
    "        self.log = True\n",
    "        self.log_gpu = False\n",
    "        self.interrupt = True\n",
    "        self.batch_alloc = None\n",
    "        self.autoscale = True\n",
    "        self.eval_only_person = False\n",
    "        self.only_last_layer = config.only_last_layer\n",
    "        self.compute_val_loss = False\n",
    "        self.max_iter = config.max_iter\n",
    "        self.trained_model = \"latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_class:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.a=1\n",
    "        self.b=2\n",
    "        self.c=3\n",
    "        self.d=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'a': 1, 'b': 2, 'c': 3, 'd': 4}\n"
    }
   ],
   "source": [
    "c = my_class()\n",
    "print(vars(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_config = {\n",
    "    \"batch_size\" : 5,\n",
    "    \"resume\" : \"yolact_data/weights/yolact_plus_base_54_800000.pth\",\n",
    "    \"start_iter\" : 0,\n",
    "    \"num_workers\" : 4,\n",
    "    \"cuda\" : True,\n",
    "    \"lr\" : 0.0001,\n",
    "    \"momentum\" : 0.9, #0.6\n",
    "    \"decay\" : None,\n",
    "    \"gamma\" : 0.1,\n",
    "    \"save_folder\" : 'weights/',\n",
    "    \"log_folder\" : 'yolact_data/logs/',\n",
    "    \"config\" : \"yolact_pp_101_ordered_rc_ucb_gait_config\",\n",
    "    \"save_interval\" : 1000, #10000\n",
    "    \"validation_size\" : 1000, #5000\n",
    "    \"validation_iter\" : 1000, #10000\n",
    "    \"keep_latest\" : False,\n",
    "    \"keep_latest_interval\" : 1000,\n",
    "    \"dataset\" : None,\n",
    "    \"log\" : True,\n",
    "    \"log_gpu\" : False,\n",
    "    \"interrupt\" : True,\n",
    "    \"batch_alloc\" : None,\n",
    "    \"autoscale\" : True,\n",
    "    \"eval_only_person\" : False,\n",
    "    \"only_last_layer\" : True,\n",
    "    \"compute_val_loss\" : False,\n",
    "    \"max_iter\" : 2000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.14<br/>\n                Syncing run <strong style=\"color:#cdcd00\">devout-plasma-179</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/josmar4321/instance_segmentation_train\" target=\"_blank\">https://wandb.ai/josmar4321/instance_segmentation_train</a><br/>\n                Run page: <a href=\"https://wandb.ai/josmar4321/instance_segmentation_train/runs/11nqcgph\" target=\"_blank\">https://wandb.ai/josmar4321/instance_segmentation_train/runs/11nqcgph</a><br/>\n                Run data is saved locally in <code>/home/josmar/proyectos/codes/02_detectron2_notebooks/P6_wandb_training/wandb/run-20210124_010651-11nqcgph</code><br/><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loading model... Done.\n/home/josmar/proyectos/codes/datasets/ucb_gait_cropped/images/crop_024-077.jpg\n/home/josmar/proyectos/codes/datasets/ucb_gait_cropped/images/crop_013-230.jpg\n/home/josmar/proyectos/codes/datasets/ucb_gait_cropped/images/crop_023-162.jpg\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 30894<br/>Program ended successfully."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>/home/josmar/proyectos/codes/02_detectron2_notebooks/P6_wandb_training/wandb/run-20210124_010651-11nqcgph/logs/debug.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>/home/josmar/proyectos/codes/02_detectron2_notebooks/P6_wandb_training/wandb/run-20210124_010651-11nqcgph/logs/debug-internal.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run summary:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>_step</td><td>0</td></tr><tr><td>_runtime</td><td>2</td></tr><tr><td>_timestamp</td><td>1611464813</td></tr></table>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h3>Run history:</h3><br/><style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n    </style><table class=\"wandb\">\n<tr><td>_step</td><td>▁</td></tr><tr><td>_runtime</td><td>▁</td></tr><tr><td>_timestamp</td><td>▁</td></tr></table><br/>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 5 W&B file(s), 9 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">devout-plasma-179</strong>: <a href=\"https://wandb.ai/josmar4321/instance_segmentation_train/runs/11nqcgph\" target=\"_blank\">https://wandb.ai/josmar4321/instance_segmentation_train/runs/11nqcgph</a><br/>\n                "
     },
     "metadata": {}
    }
   ],
   "source": [
    "global args\n",
    "    \n",
    "wandb.init(project=\"instance_segmentation_train\")\n",
    "config = wandb.config\n",
    "config.update(my_config) # Used for manual parameters\n",
    "args = Args(config)\n",
    "args.lr = config.lr\n",
    "args.momentum = config.momentum\n",
    "args.decay = config.decay\n",
    "# set_args()\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'yolact_loop.py'\n",
    "config.framework = \"pytorch\"\n",
    "predicted_images = predict_images(args, n_imgs=3)\n",
    "wandb.log({\"predictions\" : predicted_images})\n",
    "wandb.run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "dict_keys(['detection', 'net'])"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "my_preds[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-3f786850e387>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "my_preds[0]['detection']['proto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/josmar/proyectos/codes/04_casia_tests/input/people walking.jpg\"\n",
    "input_img = cv2.imread(path)\n",
    "rgb_im = input_img[:, :, ::-1]\n",
    "frame = torch.from_numpy(input_img).cuda().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w,_ = input_img.shape\n",
    "top_k = 15\n",
    "th = 0.4\n",
    "mask_alpha = 1\n",
    "\n",
    "save = cfg.rescore_bbox\n",
    "cfg.rescore_bbox = True\n",
    "t = postprocess(my_preds, w, h, visualize_lincomb = False,\n",
    "                                        crop_masks        = True,\n",
    "                                        score_threshold   = th)\n",
    "cfg.rescore_bbox = save\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = t[1].argsort(0, descending=True)[:15]\n",
    "masks = t[3][idx]\n",
    "classes, scores, boxes = [x[idx].cpu().numpy() for x in t[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dets_to_consider = min(top_k, classes.shape[0])\n",
    "for j in range(num_dets_to_consider):\n",
    "    if scores[j] < th:\n",
    "        num_dets_to_consider = j\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bin_mask= np.zeros((h, w))\n",
    "box_data = []\n",
    "class_labels = {}\n",
    "class2name = {0:\"person\"}\n",
    "for j in range(classes.shape[0]):\n",
    "    if scores[j] > th:\n",
    "        # masks\n",
    "        sil = masks[j].byte().cpu().numpy()\n",
    "        av_mask = bin_mask == 0 # Gets the pixels that are not used \n",
    "        corrected_sil = np.bitwise_and(av_mask, sil) #Gets the silhouette cropping the overlapped parts\n",
    "        bin_mask+= corrected_sil * (j+1)\n",
    "\n",
    "        # scores \n",
    "        acc = scores[j]\n",
    "        acc = round(float(acc), 2)\n",
    "\n",
    "        #boxes\n",
    "        x_min, y_min, x_max, y_max = boxes[j]\n",
    "        x_min, x_max = round(x_min/w, 2), round(x_max/w, 2)\n",
    "        y_min, y_max = round(y_min/h, 2), round(y_max/h, 2)\n",
    "        bbox_dict = {\"position\": {\n",
    "                        \"minX\": x_min,\n",
    "                        \"maxX\": x_max,\n",
    "                        \"minY\": y_min,\n",
    "                        \"maxY\": y_max},\n",
    "                    \"class_id\" : j+1,\n",
    "                    \"box_caption\": \"person:{}\".format(acc),\n",
    "                    \"scores\" : {\n",
    "                        \"acc\": acc},\n",
    "                    }\n",
    "        box_data.append(bbox_dict)\n",
    "\n",
    "        #class_labels\n",
    "        class_str = class2name[classes[j]]+ \" \" + str(j+1)\n",
    "        class_labels[j+1] = class_str\n",
    "wandb_img = wandb.Image(rgb_im, \n",
    "masks={\"prediction\" : {\"mask_data\" : bin_mask, \"class_labels\" : class_labels}},\n",
    "boxes={\"prediction\" : {\"box_data\" : box_data, \"class_labels\" : class_labels}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[{'position': {'minX': 0.39, 'maxX': 0.55, 'minY': 0.27, 'maxY': 0.9}, 'class_id': 1, 'box_caption': 'person:0.94', 'scores': {'acc': 0.94}}, {'position': {'minX': 0.54, 'maxX': 0.7, 'minY': 0.29, 'maxY': 0.9}, 'class_id': 2, 'box_caption': 'person:0.91', 'scores': {'acc': 0.91}}]\n{1: 'person 1', 2: 'person 2'}\nperson 2\n"
    }
   ],
   "source": [
    "print(box_data)\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<wandb.data_types.Image at 0x7f8270329a90>"
     },
     "metadata": {},
     "execution_count": 132
    }
   ],
   "source": [
    "wandb_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2640) must match the size of tensor b (880) at non-singleton dimension 3",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5b87e8833617>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnum_dets_to_consider\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0minv_alph_cumul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minv_alph_masks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_dets_to_consider\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmasks_color_cumul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasks_color\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minv_alph_cumul\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mmasks_color_summand\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmasks_color_cumul\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2640) must match the size of tensor b (880) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "masks_color = masks.repeat(1, 1, 1, 3) * mask_alpha\n",
    "inv_alph_masks = masks * (-mask_alpha) + 1\n",
    "        \n",
    "# I did the math for this on pen and paper. This whole block should be equivalent to:\n",
    "#    for j in range(num_dets_to_consider):\n",
    "#        img_gpu = img_gpu * inv_alph_masks[j] + masks_color[j]\n",
    "masks_color_summand = masks_color[0]\n",
    "if num_dets_to_consider > 1:\n",
    "    inv_alph_cumul = inv_alph_masks[:(num_dets_to_consider-1)].cumprod(dim=0)\n",
    "    masks_color_cumul = masks_color[1:] * inv_alph_cumul\n",
    "    masks_color_summand += masks_color_cumul.sum(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1612222753572",
   "display_name": "Python 3.6.12 64-bit ('yolact-plus': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}