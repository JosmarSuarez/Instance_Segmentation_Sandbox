{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitmask to polygonal annotation\n",
    "This notebook contains functions that allow us to transform bitmasks to polygonal annotations in COCO format\n",
    "## Main code (just for one instance per image, for more than one see bit_to_poly.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image # (pip install Pillow)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np                                 # (pip install numpy)\n",
    "from skimage import measure                        # (pip install scikit-image)\n",
    "from shapely.geometry import Polygon, MultiPolygon # (pip install Shapely)\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from pycocotools import mask\n",
    "from skimage import measure\n",
    "\n",
    "def mask_to_annotation(img_path, img_id, img_cat, ann_id, is_crowd):\n",
    "    ground_truth_binary_mask = cv2.imread(img_path,0)\n",
    "    fortran_ground_truth_binary_mask = np.asfortranarray(ground_truth_binary_mask)\n",
    "    encoded_ground_truth = mask.encode(fortran_ground_truth_binary_mask)\n",
    "    ground_truth_area = mask.area(encoded_ground_truth)\n",
    "    ground_truth_bounding_box = mask.toBbox(encoded_ground_truth)\n",
    "    contours = measure.find_contours(ground_truth_binary_mask, 0.5)\n",
    "\n",
    "    annotation = {\n",
    "            \"segmentation\": [],\n",
    "            \"area\": ground_truth_area.tolist(),\n",
    "            \"iscrowd\": is_crowd,\n",
    "            \"image_id\": img_id,\n",
    "            \"bbox\": ground_truth_bounding_box.tolist(),\n",
    "            \"category_id\": img_cat,\n",
    "            \"id\": ann_id\n",
    "        }\n",
    "\n",
    "    for contour in contours:\n",
    "        contour = np.flip(contour, axis=1)\n",
    "        segmentation = contour.ravel().tolist()\n",
    "        annotation[\"segmentation\"].append(segmentation)\n",
    "        \n",
    "    \n",
    "    return annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def images_to_annotations(dir_path, img_names):\n",
    "    #Initializing images and annotations lists\n",
    "    images=[]\n",
    "    annotations = []\n",
    "    img_names.sort()\n",
    "    img_license = 0\n",
    "    img_id=0\n",
    "    ann_id=0\n",
    "    is_crowd=0\n",
    "           \n",
    "    for img_name in img_names:\n",
    "        \n",
    "        img_path = os.path.join(dir_path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        img_size = img.shape\n",
    "        \n",
    "        img_cat = 1\n",
    "        annotation = mask_to_annotation(img_path , img_id, img_cat, ann_id, is_crowd)\n",
    "        annotations.append(annotation)\n",
    "        ann_id+=1\n",
    "            \n",
    "\n",
    "        new_img={}\n",
    "        new_img[\"license\"] = img_license\n",
    "        new_img[\"file_name\"] = img_name.split(\".\")[0]+\".jpg\" #Changed to match the video images\n",
    "        new_img[\"width\"] = img_size[1]\n",
    "        new_img[\"height\"] = img_size[0]\n",
    "        new_img[\"id\"] = img_id\n",
    "        images.append(new_img)\n",
    "\n",
    "        # sub_masks = create_sub_masks()\n",
    "        # for color, sub_mask in sub_masks.items():\n",
    "        #     plt.imshow(sub_mask)\n",
    "        #     plt.show()\n",
    "        \n",
    "        img_id+=1\n",
    "\n",
    "        sys.stdout.write('\\r'+  \"Done: {}/{}\".format(img_id,len(img_names)))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    return annotations,images\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annotation_dict(info, licenses, imgs,categories,anns):\n",
    "    my_dict = {}\n",
    "    my_dict[\"info\"]= info\n",
    "    my_dict[\"licenses\"]= licenses\n",
    "    my_dict[\"images\"]=imgs\n",
    "    my_dict[\"categories\"]=categories\n",
    "    my_dict[\"annotations\"]=anns\n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Done: 300/300"
    }
   ],
   "source": [
    "dir_path = \"/home/josmar/proyectos/codes/datasets/ucb_gait_frames/silhouettes\"\n",
    "# dir_path = '/home/josmar/proyectos/codes/datasets/casia_B1_silhouettes'\n",
    "img_names=os.listdir(dir_path)\n",
    "color2cat={\"[255 255 255]\": 1}\n",
    "info = {\n",
    "    \"description\":\"Test Dataset\",\n",
    "    \"url\":\"\",\n",
    "    \"version\":\"0.1\",\n",
    "    \"year\":2020,\n",
    "    \"contributor\":\"Josmar Suarez\",\n",
    "    \"date_created\":\"2020/07/14\"\n",
    "}\n",
    "\n",
    "licenses = [{\n",
    "        \"url\": \"\",\n",
    "        \"id\": 0,\n",
    "        \"name\": \"Attribution-NonCommercial-ShareAlike License\"\n",
    "    }]\n",
    "categories = [\n",
    "    {\n",
    "        \"supercategory\":\"person\",\n",
    "        \"id\":1,\n",
    "        \"name\":\"person\"\n",
    "    }\n",
    "]\n",
    "anns,imgs = images_to_annotations(dir_path, img_names)\n",
    "my_dict = create_annotation_dict(info, licenses, imgs,categories,anns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating train,val, test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "9840 1230 1230\n"
    }
   ],
   "source": [
    "import random\n",
    "#percent of ____ from 0 to 1\n",
    "p_train = 0.8\n",
    "p_val = 0.1\n",
    "p_test = 0.1\n",
    "\n",
    "#Reading and shuffling images list\n",
    "dir_path = \"/home/josmar/proyectos/codes/datasets/ucb_gait_frames/silhouettes\"\n",
    "all_images = os.listdir(dir_path)\n",
    "random.shuffle(all_images)\n",
    "# Length of the image list\n",
    "n = len(all_images)\n",
    "# Limits of the index\n",
    "lim1 = int(p_train*n)\n",
    "lim2 = lim1 + int(p_val*n)\n",
    "# Creating lists for each value\n",
    "train_l = all_images[0:lim1]\n",
    "val_l = all_images[lim1:lim2]\n",
    "test_l = all_images[lim2:n]\n",
    "# Visualizing sizes\n",
    "print(len(train_l),len(val_l),len(test_l))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n Ucb Gait Train\nDone: 9840/9840\n Ucb Gait Val\nDone: 1230/1230\n Ucb Gait Test\nDone: 1230/1230"
    }
   ],
   "source": [
    "dir_path = \"/home/josmar/proyectos/codes/datasets/ucb_gait_frames/silhouettes\"\n",
    "# dir_path = '/home/josmar/proyectos/codes/datasets/casia_B1_silhouettes'\n",
    "all_dicts = [] \n",
    "datasets = [train_l,val_l,test_l]\n",
    "titles = [\"Ucb Gait Train\",\"Ucb Gait Val\", \"Ucb Gait Test\"]\n",
    "index=0\n",
    "for l in [train_l,val_l,test_l]:\n",
    "    color2cat={\"[255 255 255]\": 1}\n",
    "    info = {\n",
    "        \"description\":titles[index],\n",
    "        \"url\":\"\",\n",
    "        \"version\":\"0.1\",\n",
    "        \"year\":2020,\n",
    "        \"contributor\":\"Josmar Suarez\",\n",
    "        \"date_created\":\"2020/10/28\"\n",
    "    }\n",
    "\n",
    "    licenses = [{\n",
    "            \"url\": \"\",\n",
    "            \"id\": 0,\n",
    "            \"name\": \"Attribution-NonCommercial-ShareAlike License\"\n",
    "        }]\n",
    "    categories = [\n",
    "        {\n",
    "            \"supercategory\":\"person\",\n",
    "            \"id\":1,\n",
    "            \"name\":\"person\"\n",
    "        }\n",
    "    ]\n",
    "    print(\"\\n\",titles[index])\n",
    "    anns,imgs = images_to_annotations(dir_path, l)\n",
    "    my_dict = create_annotation_dict(info, licenses, imgs,categories,anns)\n",
    "    all_dicts.append(my_dict)\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "titles = [\"ucb_gait_train.json\",\"ucb_gait_val.json\", \"ucb_gait_test.json\"]\n",
    "index=0\n",
    "for my_dict in all_dicts:\n",
    "    with open(titles[index], 'w') as fp:\n",
    "        json.dump(my_dict, fp)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "30"
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "len(all_dicts[2][\"annotations\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the annotations in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "with open('ucb_gait_poly_new.json', 'w') as fp:\n",
    "    json.dump(my_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'license': 0,\n 'file_name': '002-000.jpg',\n 'width': 1280,\n 'height': 720,\n 'id': 0}"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "my_dict[\"images\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting all silhouetes and images in datasets\n",
    "```\n",
    "import glob \n",
    "import shutil\n",
    "\n",
    "    \n",
    "destination_path = \"/home/josmar/proyectos/codes/datasets/ucb_gait_frames/silhouettes\"\n",
    "pattern = \"/home/josmar/proyectos/codes/annotation_tools/background_substraction/bin_close_images/*/silhouette/*\"  \n",
    "for img in glob.glob(pattern):\n",
    "    shutil.copy(img, destination_path)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviewing dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "with open('/home/josmar/proyectos/codes/datasets/ucb_gait_frames/ucb_gait_poly.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{3368}\n"
    }
   ],
   "source": [
    "lengths=[]\n",
    "for ann in data[\"annotations\"]:\n",
    "    l=len(data[\"annotations\"][0][\"segmentation\"][0])\n",
    "    lengths.append(l)\n",
    "print(set(lengths))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1603903962073",
   "display_name": "Python 3.6.10 64-bit ('backmat': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}